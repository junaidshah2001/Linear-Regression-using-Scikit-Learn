# Linear-Regression-using-Scikit-Learn
This repository contains solutions and experiments from Week 2 of Andrew Ng's Machine Learning Specialization (Coursera), focusing on:  
Feature Engineering

Polynomial Regression

Gradient Descent

Modeling with Scikit-learn

ğŸš€ What I Learned
ğŸ”§ Feature Engineering
Created new features from raw data to better capture patterns (e.g., xÂ³, âˆšx)

Improved model accuracy by transforming inputs into more expressive features

ğŸ“ˆ Polynomial Regression
Extended linear regression with polynomial terms to fit non-linear trends

Explored quadratic and cubic models to fit complex housing price data

ğŸ“Š Scikit-learn & Gradient Descent
Applied scikit-learn's LinearRegression and SGDRegressor

Practiced both analytical and iterative optimization approaches

Understood the importance of feature scaling in gradient-based methods

ğŸ›  Technologies Used
Python ğŸ

NumPy

Pandas

Matplotlib & Seaborn (for visualization)

Scikit-learn (for regression modeling)

ğŸ“ How to Run
Clone this repository:

bash
Copy
Edit
git clone https://github.com/junaidshah2001/Linear-Regression-using-Scikit-Learn

cd Feature-Engineering-Polynomial-Regression
Open the notebooks using Jupyter or VSCode

Run cells step-by-step and experiment with new features or regression degrees

ğŸ”— Live Notebook Preview (via nbviewer)
Feature Engineering & Polynomial Regression:
View Notebook

Scikit-learn with Gradient Descent:
View Notebook

ğŸ“Œ Author
Syed Ali Raza Shah Bukhari
Aspiring Data Scientist & ML Engineer
www.linkedin.com/in/junaidshah2001

ğŸŒŸ Acknowledgments
Machine Learning Specialization by Andrew Ng

Coursera Labs and DeepLearning.AI for practical assignments

scikit-learn for easy-to-use ML tools
