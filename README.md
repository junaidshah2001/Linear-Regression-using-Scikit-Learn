# Linear-Regression-using-Scikit-Learn
This repository contains solutions and experiments from Week 2 of Andrew Ng's Machine Learning Specialization (Coursera), focusing on:  
Feature Engineering

Polynomial Regression

Gradient Descent

Modeling with Scikit-learn

🚀 What I Learned
🔧 Feature Engineering
Created new features from raw data to better capture patterns (e.g., x³, √x)

Improved model accuracy by transforming inputs into more expressive features

📈 Polynomial Regression
Extended linear regression with polynomial terms to fit non-linear trends

Explored quadratic and cubic models to fit complex housing price data

📊 Scikit-learn & Gradient Descent
Applied scikit-learn's LinearRegression and SGDRegressor

Practiced both analytical and iterative optimization approaches

Understood the importance of feature scaling in gradient-based methods

🛠 Technologies Used
Python 🐍

NumPy

Pandas

Matplotlib & Seaborn (for visualization)

Scikit-learn (for regression modeling)

📎 How to Run
Clone this repository:

bash
Copy
Edit
git clone https://github.com/junaidshah2001/Linear-Regression-using-Scikit-Learn

cd Feature-Engineering-Polynomial-Regression
Open the notebooks using Jupyter or VSCode

Run cells step-by-step and experiment with new features or regression degrees

🔗 Live Notebook Preview (via nbviewer)
Feature Engineering & Polynomial Regression:
View Notebook

Scikit-learn with Gradient Descent:
View Notebook

📌 Author
Syed Ali Raza Shah Bukhari
Aspiring Data Scientist & ML Engineer
www.linkedin.com/in/junaidshah2001

🌟 Acknowledgments
Machine Learning Specialization by Andrew Ng

Coursera Labs and DeepLearning.AI for practical assignments

scikit-learn for easy-to-use ML tools
